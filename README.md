# <center>Ã‰cole nationale de la statistique et de l'analyse Ã©conomique (ENSAE) - Pierre NDIAYE</center>
## <center>Projet de Web Scraping</center>
### <center>ğŸ“° Analyse des tendances mÃ©diatiques, topic modeling</center>

<center>RÃ©alisÃ© par :</center>  
<center><strong>Ahmed Firhoun OUMAROU SOULEYE</strong></center>  
<center><strong>Mamadou SaÃ¯dou DIALLO</strong></center>  
<center><em>Ã‰tudiants en AS3 - Option Data Science</em></center>

<center>Cours tenu par :</center>  
<center><strong>M. Baye Demba DIACK</strong></center>  
<center><em>Chef du Bureau des DonnÃ©es et des Solutions informatique (BDSI)</em></center>  
<center>AnnÃ©e acadÃ©mique 2024-2025</center>

---

> Collecte automatisÃ©e et analyse des tendances d'actualitÃ©s sÃ©nÃ©galaises avec du Topic Modeling LDA

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![GitHub Actions](https://img.shields.io/badge/CI/CD-GitHub%20Actions-orange.svg)](https://github.com/features/actions)

## ğŸ¯ Description

Ce projet automatise la collecte d'articles de presse sÃ©nÃ©galais depuis **SeneWeb** et **Senego**, puis utilise des techniques de **Topic Modeling** avec l'algorithme **LDA (Latent Dirichlet Allocation)** pour identifier les sujets d'actualitÃ© les plus populaires.

### âœ¨ FonctionnalitÃ©s principales
- ğŸ•·ï¸ **Web scraping automatisÃ©** des sites d'actualitÃ©s sÃ©nÃ©galais
- ğŸ§  **Topic Modeling** avec LDA pour identifier les tendances
- âš™ï¸ **Automatisation complÃ¨te** via GitHub Actions
- ğŸ“Š **Interface interactive** avec Dash (voir dÃ©pÃ´t sÃ©parÃ©)
- ğŸ”„ **RÃ©entraÃ®nement pÃ©riodique** des modÃ¨les

## ğŸ—ï¸ Architecture du Projet

```
â”œâ”€â”€ ğŸ“„ articles_scraped.csv      # DonnÃ©es collectÃ©es
â”œâ”€â”€ ğŸ scraper.py               # Script de scraping
â”œâ”€â”€ ğŸ§  lda.py                   # ModÃ¨le Topic Modeling
â”œâ”€â”€ ğŸ““ Notebook_NLP.ipynb       # Analyse exploratoire
â”œâ”€â”€ ğŸ“‹ requirements.txt         # DÃ©pendances Python
â”œâ”€â”€ .github/workflows/          # Automatisation CI/CD
â”‚   â”œâ”€â”€ scrape.yml             # Scraping quotidien
â”‚   â””â”€â”€ lda.yml                # RÃ©entraÃ®nement hebdomadaire
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ architecture.pptx      # Document d'architecture
â”‚   â”œâ”€â”€ resume_projet.docx     # RÃ©sumÃ© du projet
â”‚   â””â”€â”€ Liens.txt             # Liens utiles
â””â”€â”€ models/                    # ModÃ¨les sauvegardÃ©s
    â”œâ”€â”€ best_lda_model.joblib  # ModÃ¨le LDA optimisÃ©
    â””â”€â”€ vectorizer.joblib      # Vectoriseur de texte
```

## ğŸš€ Installation

### PrÃ©requis
- Python 3.12+
- Git

### Installation des dÃ©pendances
```bash
git clone https://github.com/votre-username/actu-scraping-lda.git
cd actu-scraping-lda
pip install -r requirements.txt
```

## ğŸ“– Utilisation

### 1. Scraping manuel
```bash
python scraper.py
```
Collecte les derniers articles depuis SeneWeb et Senego et les sauvegarde dans `articles_scraped.csv`.

### 2. EntraÃ®nement du modÃ¨le LDA
```bash
python lda.py
```
- Charge les donnÃ©es depuis le CSV
- PrÃ©processe le texte (nettoyage, tokenisation)
- EntraÃ®ne le modÃ¨le LDA
- Sauvegarde le meilleur modÃ¨le dans `/models/`

### 3. Analyse exploratoire
Ouvrez `Notebook_NLP.ipynb` dans Jupyter pour explorer les donnÃ©es et visualiser les rÃ©sultats du Topic Modeling.

## ğŸ¤– Automatisation

Le projet utilise **GitHub Actions** pour automatiser les tÃ¢ches :

### Scraping Quotidien
- **DÃ©clencheur** : Tous les jours Ã  6h UTC
- **Action** : ExÃ©cute `scraper.py` et commit les nouvelles donnÃ©es
- **Fichier** : `.github/workflows/scrape.yml`

### RÃ©entraÃ®nement Hebdomadaire
- **DÃ©clencheur** : Tous les dimanches
- **Action** : RÃ©entraÃ®ne le modÃ¨le LDA avec les nouvelles donnÃ©es
- **Fichier** : `.github/workflows/lda.yml`

## ğŸ› ï¸ Technologies UtilisÃ©es

### Backend
- **Python 3.12** - Langage principal
- **Scikit-learn** - Algorithme LDA
- **NLTK** - Traitement du langage naturel
- **Pandas** - Manipulation des donnÃ©es
- **BeautifulSoup** - Web scraping

### Infrastructure
- **GitHub Actions** - CI/CD et automatisation
- **Joblib** - SÃ©rialisation des modÃ¨les
- **CSV** - Stockage des donnÃ©es

## ğŸ“Š DonnÃ©es CollectÃ©es

Pour chaque article, les informations suivantes sont extraites :
- **Titre** - Titre de l'article
- **Date** - Date de publication
- **Contenu** - Texte complet de l'article
- **Source** - Site web source (SeneWeb/Senego)
- **URL** - Lien vers l'article original

## ğŸ§  Topic Modeling

### Processus LDA
1. **PrÃ©processing** : Nettoyage du texte, suppression des mots vides
2. **Vectorisation** : Transformation du texte en vecteurs TF-IDF
3. **ModÃ©lisation** : Application de l'algorithme LDA
4. **Ã‰valuation** : Calcul du Coherence Score
5. **Sauvegarde** : Stockage du meilleur modÃ¨le

### MÃ©triques d'Ã©valuation
- **Coherence Score** : Mesure la cohÃ©rence sÃ©mantique des topics
- **Perplexity** : Ã‰value la qualitÃ© prÃ©dictive du modÃ¨le

## ğŸ“ˆ Monitoring et Performance

### MÃ©triques suivies
- Nombre d'articles collectÃ©s par jour
- Performance du scraping (taux de succÃ¨s)
- QualitÃ© des topics identifiÃ©s
- Temps d'exÃ©cution des processus

## ğŸ”§ Configuration

### Variables d'environnement
Aucune variable d'environnement requise pour l'utilisation de base.

### Personnalisation
- **Sources** : Modifiez `scraper.py` pour ajouter d'autres sites
- **ModÃ¨le** : Ajustez les paramÃ¨tres LDA dans `lda.py`
- **FrÃ©quence** : Modifiez les cron dans les workflows GitHub Actions

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©ez une branche feature (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Committez vos changements (`git commit -m 'Ajout nouvelle fonctionnalitÃ©'`)
4. Push vers la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. Ouvrez une Pull Request

## ğŸ“ Roadmap

- [ ] Extension Ã  d'autres sources (Le Soleil, BBC Afrique)
- [ ] Analyse de sentiment
- [ ] Support multilingue (franÃ§ais/wolof)
- [ ] API REST pour accÃ¨s externe
- [ ] DÃ©tection automatique d'Ã©vÃ©nements

## ğŸ› ProblÃ¨mes Connus

- Le scraping peut Ã©chouer si les sites changent leur structure HTML
- Les modÃ¨les peuvent nÃ©cessiter un rÃ©ajustement avec l'Ã©volution du vocabulaire

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ‘¥ Auteurs

- **Ahmed Firhoun OUMAROU SOULEYE** - *Ã‰tudiant AS3 Data Science* - [@ahmed-github](https://github.com/ahmed-username)
- **Mamadou SaÃ¯dou DIALLO** - *Ã‰tudiant AS3 Data Science* - [@mamadou-github](https://github.com/mamadou-username)

## ğŸ« Contexte AcadÃ©mique

Ce projet s'inscrit dans le cadre du cours de Web Scraping dispensÃ© par **M. Baye Demba DIACK**, Chef du Bureau des DonnÃ©es et des Solutions informatique (BDSI) Ã  l'Ã‰cole nationale de la statistique et de l'analyse Ã©conomique (ENSAE) - Pierre NDIAYE.

## ğŸ™ Remerciements

- **M. Baye Demba DIACK** pour son encadrement et ses conseils prÃ©cieux
- L'**ENSAE Pierre NDIAYE** pour le cadre acadÃ©mique et les ressources mises Ã  disposition
- **SeneWeb** et **Senego** pour les donnÃ©es d'actualitÃ©s accessibles
- La communautÃ© open-source pour les outils utilisÃ©s
- Les contributeurs du projet

---

â­ N'oubliez pas de mettre une Ã©toile si ce projet vous a Ã©tÃ© utile !

name: Weekly LDA Model Retraining

on:
  schedule:
    - cron: '0 5 * * 1'  # Tous les lundis Ã  5h UTC
  workflow_dispatch:     # Permet un dÃ©clenchement manuel
    inputs:
      force_retrain:
        description: 'Forcer le rÃ©entraÃ®nement mÃªme avec peu de donnÃ©es'
        required: false
        default: false
        type: boolean
      n_trials:
        description: 'Nombre d essais pour l optimisation'
        required: false
        default: '30'
        type: string

jobs:
  retrain-lda:
    runs-on: ubuntu-latest
    timeout-minutes: 45  # Limite de temps pour Ã©viter les blocages
    
    permissions:
      contents: write
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-lda-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-lda-
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Check data availability
        id: check_data
        run: |
          if [ -f "articles_scraped.csv" ]; then
            article_count=$(python -c "
            import pandas as pd
            try:
                df = pd.read_csv('articles_scraped.csv')
                print(len(df.dropna(subset=['contenu'])))
            except Exception as e:
                print('0')
            " 2>/dev/null || echo "0")
            echo "article_count=$article_count" >> $GITHUB_OUTPUT
            echo "ğŸ“Š Articles avec contenu: $article_count"
            
            # VÃ©rifier si on a assez de donnÃ©es pour l'entraÃ®nement
            if [ "$article_count" -ge 50 ]; then
              echo "sufficient_data=true" >> $GITHUB_OUTPUT
              echo "âœ… DonnÃ©es suffisantes pour l'entraÃ®nement"
            else
              echo "sufficient_data=false" >> $GITHUB_OUTPUT
              echo "âš ï¸ DonnÃ©es insuffisantes ($article_count articles, minimum 50 requis)"
            fi
          else
            echo "article_count=0" >> $GITHUB_OUTPUT
            echo "sufficient_data=false" >> $GITHUB_OUTPUT
            echo "âŒ Fichier articles_scraped.csv introuvable"
          fi
          
      - name: Create models directory
        run: |
          mkdir -p models
          echo "ğŸ“ RÃ©pertoire models crÃ©Ã©/vÃ©rifiÃ©"
          
      - name: Backup existing model
        run: |
          if [ -f "models/best_lda_model.joblib" ]; then
            cp "models/best_lda_model.joblib" "models/best_lda_model_backup_$(date +%Y%m%d).joblib"
            echo "ğŸ’¾ ModÃ¨le existant sauvegardÃ©"
          else
            echo "ğŸ“„ Aucun modÃ¨le existant Ã  sauvegarder"
          fi
          
      - name: Modify LDA script for workflow
        run: |
          # CrÃ©er une version modifiÃ©e de lda.py pour le workflow
          cat > lda_workflow.py << 'EOF'
          import sys
          import os
          import pandas as pd
          import re
          import nltk
          from nltk.corpus import stopwords
          from unidecode import unidecode
          from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS
          from sklearn.decomposition import LatentDirichletAllocation
          from sklearn.model_selection import train_test_split
          from wordcloud import STOPWORDS
          import optuna
          import joblib
          from datetime import datetime
          import logging
          
          # Configuration du logging
          logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
          logger = logging.getLogger(__name__)
          
          def main():
              try:
                  # ParamÃ¨tres depuis les arguments
                  n_trials = int(sys.argv[1]) if len(sys.argv) > 1 else 30
                  force_retrain = sys.argv[2].lower() == 'true' if len(sys.argv) > 2 else False
                  
                  logger.info(f"ğŸš€ DÃ©marrage entraÃ®nement LDA - {n_trials} essais")
                  
                  # Charger les donnÃ©es
                  if not os.path.exists("articles_scraped.csv"):
                      logger.error("âŒ Fichier articles_scraped.csv introuvable")
                      sys.exit(1)
                  
                  df = pd.read_csv("articles_scraped.csv")
                  initial_count = len(df)
                  df = df.dropna(subset=['contenu'])
                  final_count = len(df)
                  
                  logger.info(f"ğŸ“Š {initial_count} articles initiaux, {final_count} avec contenu")
                  
                  if final_count < 50 and not force_retrain:
                      logger.warning(f"âš ï¸ DonnÃ©es insuffisantes ({final_count} < 50)")
                      sys.exit(1)
                  
                  # Initialisation NLTK
                  try:
                      nltk.download('stopwords', quiet=True)
                      logger.info("âœ… Stopwords NLTK tÃ©lÃ©chargÃ©s")
                  except Exception as e:
                      logger.warning(f"âš ï¸ Erreur tÃ©lÃ©chargement stopwords: {e}")
                  
                  # Stopwords (identiques Ã  lda.py)
                  custom_stopwords = set(STOPWORDS)
                  try:
                      custom_stopwords.update(stopwords.words('french'))
                  except:
                      logger.warning("âš ï¸ Stopwords franÃ§ais non disponibles")
                  custom_stopwords.update(ENGLISH_STOP_WORDS)
                  custom_stopwords.update([
                      'selon', 'ce', 'cet', 'cette', 'dont', 'ainsi', 'hgroupe', 'ete', 'aussi','field','plus',
                      'dun', 'dune', 'cest', 'comme', 'juin', 'apres', 'deux', 'senegal','senegalais','juingroupe',
                      'sest','lors','egalement','sans','notamment', 'quil', 'tout', 'tous', 'fait','entre',
                      'titre','plusieurs','sous','faire','bien','meme','avant','toujours','cela','face','tres',
                      'leur','leurs','toute','toutes','vers','quelle','jai','etait','etais','senegalaise',
                      'alors','encore','avoir','nest', 'etre',
                  ])
                  
                  # PrÃ©traitement (identique Ã  lda.py)
                  def preprocess(text):
                      if pd.isna(text):
                          return ""
                      text = str(text).lower()
                      text = unidecode(text)
                      text = re.sub(r'\d+', '', text)
                      text = re.sub(r'[^\w\s]', '', text)
                      tokens = text.split()
                      tokens = [word for word in tokens if word not in custom_stopwords and len(word) > 2]
                      return ' '.join(tokens)
                  
                  logger.info("ğŸ”„ PrÃ©traitement des textes...")
                  df['cleaned_content'] = df['contenu'].apply(preprocess)
                  
                  # Filtrer les textes vides aprÃ¨s prÃ©traitement
                  df = df[df['cleaned_content'].str.len() > 10]
                  logger.info(f"ğŸ“ {len(df)} articles aprÃ¨s prÃ©traitement")
                  
                  if len(df) < 20:
                      logger.error("âŒ Trop peu d'articles aprÃ¨s prÃ©traitement")
                      sys.exit(1)
                  
                  # Vectorisation (identique Ã  lda.py)
                  logger.info("ğŸ”¤ Vectorisation...")
                  vectorizer = CountVectorizer(max_df=0.95, min_df=2)
                  X = vectorizer.fit_transform(df['cleaned_content'])
                  
                  logger.info(f"ğŸ“Š Matrice: {X.shape[0]} documents, {X.shape[1]} mots")
                  
                  # Division train/validation
                  X_train, X_val = train_test_split(X, test_size=0.2, random_state=42)
                  
                  # Optimisation avec Optuna (identique Ã  lda.py)
                  def objective(trial):
                      n_components = trial.suggest_int('n_components', 3, 15)
                      learning_decay = trial.suggest_float('learning_decay', 0.5, 0.9)
                      learning_offset = trial.suggest_int('learning_offset', 10, 100)
                      
                      lda = LatentDirichletAllocation(
                          n_components=n_components,
                          learning_method='online',
                          learning_decay=learning_decay,
                          learning_offset=learning_offset,
                          max_iter=10,
                          random_state=42
                      )
                      
                      try:
                          lda.fit(X_train)
                          perplexity = lda.perplexity(X_val)
                          return perplexity
                      except Exception as e:
                          logger.warning(f"âš ï¸ Erreur trial: {e}")
                          return float('inf')
                  
                  logger.info(f"ğŸ¯ Optimisation hyperparamÃ¨tres ({n_trials} essais)...")
                  study = optuna.create_study(direction='minimize')
                  study.optimize(objective, n_trials=n_trials, show_progress_bar=False)
                  
                  best_params = study.best_params
                  logger.info(f"âœ… Meilleurs paramÃ¨tres: {best_params}")
                  logger.info(f"ğŸ“Š Meilleure perplexitÃ©: {study.best_value:.2f}")
                  
                  # EntraÃ®nement final (identique Ã  lda.py)
                  logger.info("ğŸ‹ï¸ EntraÃ®nement final...")
                  best_lda = LatentDirichletAllocation(
                      n_components=best_params['n_components'],
                      learning_method='online',
                      learning_decay=best_params['learning_decay'],
                      learning_offset=best_params['learning_offset'],
                      max_iter=20,
                      random_state=42
                  )
                  
                  best_lda.fit(X)
                  
                  # Sauvegarde (identique Ã  lda.py)
                  os.makedirs('./models', exist_ok=True)
                  model_path = './models/best_lda_model.joblib'
                  joblib.dump(best_lda, model_path)
                  
                  # Sauvegarder aussi le vectorizer
                  vectorizer_path = './models/vectorizer.joblib'
                  joblib.dump(vectorizer, vectorizer_path)
                  
                  logger.info("ğŸ’¾ Sauvegarde du modÃ¨le...")
                  logger.info("âœ… ModÃ¨le sauvegardÃ© avec succÃ¨s!")
                  
                  # Test de chargement (identique Ã  lda.py)
                  logger.info("ğŸ” Test de chargement...")
                  try:
                      test_model = joblib.load(model_path)
                      test_vectorizer = joblib.load(vectorizer_path)
                      logger.info("âœ… Test de chargement rÃ©ussi!")
                  except Exception as e:
                      logger.error(f"âŒ Erreur test chargement: {e}")
                      sys.exit(1)
                  
                  # MÃ©tadonnÃ©es
                  metadata = {
                      'timestamp': datetime.now().isoformat(),
                      'n_documents': len(df),
                      'n_features': X.shape[1],
                      'best_params': best_params,
                      'best_perplexity': study.best_value,
                      'n_trials': n_trials
                  }
                  
                  import json
                  with open('./models/model_metadata.json', 'w') as f:
                      json.dump(metadata, f, indent=2)
                  
                  logger.info(f"ğŸ’¾ ModÃ¨le sauvegardÃ©: {model_path}")
                  logger.info(f"ğŸ‰ EntraÃ®nement terminÃ© avec succÃ¨s!")
                  
                  print(f"SUCCESS:{best_params['n_components']}:{study.best_value:.2f}:{len(df)}")
                  
              except Exception as e:
                  logger.error(f"âŒ Erreur gÃ©nÃ©rale: {e}")
                  import traceback
                  traceback.print_exc()
                  sys.exit(1)
          
          if __name__ == "__main__":
              main()
          EOF
          
      - name: Run LDA training
        id: training
        if: steps.check_data.outputs.sufficient_data == 'true' || github.event.inputs.force_retrain == 'true'
        run: |
          echo "ğŸš€ Lancement de l'entraÃ®nement LDA..."
          
          N_TRIALS="${{ github.event.inputs.n_trials || '30' }}"
          FORCE_RETRAIN="${{ github.event.inputs.force_retrain || 'false' }}"
          
          # Utiliser le script modifiÃ© au lieu de lda.py directement
          python lda_workflow.py "$N_TRIALS" "$FORCE_RETRAIN" 2>&1 | tee training_log.txt
          
          # Capturer les rÃ©sultats
          if grep -q "SUCCESS:" training_log.txt; then
            RESULT_LINE=$(grep "SUCCESS:" training_log.txt | tail -1)
            N_TOPICS=$(echo $RESULT_LINE | cut -d: -f2)
            PERPLEXITY=$(echo $RESULT_LINE | cut -d: -f3)
            N_DOCS=$(echo $RESULT_LINE | cut -d: -f4)
            
            echo "training_success=true" >> $GITHUB_OUTPUT
            echo "n_topics=$N_TOPICS" >> $GITHUB_OUTPUT
            echo "perplexity=$PERPLEXITY" >> $GITHUB_OUTPUT
            echo "n_documents=$N_DOCS" >> $GITHUB_OUTPUT
            
            echo "âœ… EntraÃ®nement rÃ©ussi!"
            echo "ğŸ“Š Topics: $N_TOPICS, PerplexitÃ©: $PERPLEXITY, Documents: $N_DOCS"
          else
            echo "training_success=false" >> $GITHUB_OUTPUT
            echo "âŒ Ã‰chec de l'entraÃ®nement"
          fi
          
      - name: Generate model report
        if: steps.training.outputs.training_success == 'true'
        run: |
          cat > generate_model_report.py << 'EOF'
          import joblib
          import json
          import os
          from datetime import datetime
          
          def generate_report():
              try:
                  # Charger les mÃ©tadonnÃ©es
                  if os.path.exists('./models/model_metadata.json'):
                      with open('./models/model_metadata.json', 'r') as f:
                          metadata = json.load(f)
                  else:
                      metadata = {}
                  
                  # GÃ©nÃ©rer le rapport
                  report = []
                  report.append("# ğŸ“Š Rapport d'EntraÃ®nement LDA")
                  report.append(f"**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}")
                  report.append("")
                  report.append("## ğŸ¯ RÃ©sultats")
                  report.append(f"- **Nombre de topics:** {metadata.get('best_params', {}).get('n_components', 'N/A')}")
                  report.append(f"- **PerplexitÃ©:** {metadata.get('best_perplexity', 'N/A'):.2f}" if isinstance(metadata.get('best_perplexity'), (int, float)) else f"- **PerplexitÃ©:** {metadata.get('best_perplexity', 'N/A')}")
                  report.append(f"- **Documents traitÃ©s:** {metadata.get('n_documents', 'N/A')}")
                  report.append(f"- **Vocabulaire:** {metadata.get('n_features', 'N/A')} mots")
                  report.append("")
                  report.append("## âš™ï¸ HyperparamÃ¨tres")
                  best_params = metadata.get('best_params', {})
                  for param, value in best_params.items():
                      report.append(f"- **{param}:** {value}")
                  report.append("")
                  report.append("## ğŸ“ Fichiers gÃ©nÃ©rÃ©s")
                  report.append("- `best_lda_model.joblib` - ModÃ¨le LDA")
                  report.append("- `vectorizer.joblib` - Vectoriseur")
                  report.append("- `model_metadata.json` - MÃ©tadonnÃ©es")
                  
                  with open('model_report.md', 'w', encoding='utf-8') as f:
                      f.write('\n'.join(report))
                  
                  print("ğŸ“‹ Rapport gÃ©nÃ©rÃ© avec succÃ¨s")
                  
              except Exception as e:
                  print(f"âŒ Erreur gÃ©nÃ©ration rapport: {e}")
          
          if __name__ == "__main__":
              generate_report()
          EOF
          
          python generate_model_report.py
          
      - name: Commit and push model updates
        if: steps.training.outputs.training_success == 'true'
        run: |
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Ajouter les fichiers du modÃ¨le
          git add models/
          
          # VÃ©rifier s'il y a des changements
          if ! git diff --cached --quiet; then
            # Message de commit informatif
            N_TOPICS="${{ steps.training.outputs.n_topics }}"
            PERPLEXITY="${{ steps.training.outputs.perplexity }}"
            N_DOCS="${{ steps.training.outputs.n_documents }}"
            TIMESTAMP=$(date +'%Y-%m-%d %H:%M UTC')
            
            git commit -m "ğŸ¤– Weekly LDA model update - ${N_TOPICS} topics, perplexity ${PERPLEXITY} (${N_DOCS} docs) - ${TIMESTAMP}"
            git push origin master
            
            echo "âœ… ModÃ¨le mis Ã  jour et poussÃ© avec succÃ¨s"
            echo "ğŸ“Š ${N_TOPICS} topics, perplexitÃ© ${PERPLEXITY}"
          else
            echo "â„¹ï¸ Aucun changement dÃ©tectÃ© dans le modÃ¨le"
          fi
          
      - name: Upload training artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lda-training-${{ github.run_number }}
          path: |
            training_log.txt
            model_report.md
            models/model_metadata.json
          retention-days: 30
          
      - name: Final status report
        if: always()
        run: |
          echo "=== ğŸ“Š RAPPORT FINAL LDA ==="
          
          if [ "${{ steps.check_data.outputs.sufficient_data }}" == "true" ] || [ "${{ github.event.inputs.force_retrain }}" == "true" ]; then
            if [ "${{ steps.training.outputs.training_success }}" == "true" ]; then
              echo "âœ… **SUCCÃˆS** - ModÃ¨le LDA rÃ©entraÃ®nÃ© avec succÃ¨s"
              echo "ğŸ“Š Topics: ${{ steps.training.outputs.n_topics }}"
              echo "ğŸ“ˆ PerplexitÃ©: ${{ steps.training.outputs.perplexity }}"
              echo "ğŸ“„ Documents: ${{ steps.training.outputs.n_documents }}"
            else
              echo "âŒ **Ã‰CHEC** - Erreur pendant l'entraÃ®nement"
            fi
          else
            echo "âš ï¸ **SAUTÃ‰** - DonnÃ©es insuffisantes (${{ steps.check_data.outputs.article_count }} articles)"
            echo "ğŸ’¡ Utilisez force_retrain=true pour forcer l'entraÃ®nement"
          fi
          
          echo "ğŸ“… Prochain entraÃ®nement: Lundi prochain Ã  5h UTC"
          
      - name: Cleanup temporary files
        if: always()
        run: |
          # Nettoyer les fichiers temporaires
          rm -f lda_workflow.py generate_model_report.py
          rm -f training_log.txt model_report.md
          
          echo "ğŸ§¹ Nettoyage terminÃ©"
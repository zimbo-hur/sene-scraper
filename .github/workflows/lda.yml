name: Weekly LDA Model Retraining

on:
  schedule:
    - cron: '0 5 * * 1'  # Tous les lundis à 5h UTC
  workflow_dispatch:     # Permet un déclenchement manuel
    inputs:
      force_retrain:
        description: 'Forcer le réentraînement même avec peu de données'
        required: false
        default: false
        type: boolean
      n_trials:
        description: 'Nombre d essais pour l optimisation'
        required: false
        default: '30'
        type: string

jobs:
  retrain-lda:
    runs-on: ubuntu-latest
    timeout-minutes: 45  # Limite de temps pour éviter les blocages
    
    permissions:
      contents: write
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-lda-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-lda-
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Check data availability
        id: check_data
        run: |
          if [ -f "articles_scraped.csv" ]; then
            article_count=$(python -c "
            import pandas as pd
            try:
                df = pd.read_csv('articles_scraped.csv')
                print(len(df.dropna(subset=['contenu'])))
            except Exception as e:
                print('0')
            " 2>/dev/null || echo "0")
            echo "article_count=$article_count" >> $GITHUB_OUTPUT
            echo "📊 Articles avec contenu: $article_count"
            
            # Vérifier si on a assez de données pour l'entraînement
            if [ "$article_count" -ge 50 ]; then
              echo "sufficient_data=true" >> $GITHUB_OUTPUT
              echo "✅ Données suffisantes pour l'entraînement"
            else
              echo "sufficient_data=false" >> $GITHUB_OUTPUT
              echo "⚠️ Données insuffisantes ($article_count articles, minimum 50 requis)"
            fi
          else
            echo "article_count=0" >> $GITHUB_OUTPUT
            echo "sufficient_data=false" >> $GITHUB_OUTPUT
            echo "❌ Fichier articles_scraped.csv introuvable"
          fi
          
      - name: Create models directory
        run: |
          mkdir -p models
          echo "📁 Répertoire models créé/vérifié"
          
      - name: Backup existing model
        run: |
          if [ -f "models/best_lda_model.joblib" ]; then
            cp "models/best_lda_model.joblib" "models/best_lda_model_backup_$(date +%Y%m%d).joblib"
            echo "💾 Modèle existant sauvegardé"
          else
            echo "📄 Aucun modèle existant à sauvegarder"
          fi
          
      - name: Modify LDA script for workflow
        run: |
          # Créer une version modifiée de lda.py pour le workflow
          cat > lda_workflow.py << 'EOF'
          import sys
          import os
          import pandas as pd
          import re
          import nltk
          from nltk.corpus import stopwords
          from unidecode import unidecode
          from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS
          from sklearn.decomposition import LatentDirichletAllocation
          from sklearn.model_selection import train_test_split
          from wordcloud import STOPWORDS
          import optuna
          import joblib
          from datetime import datetime
          import logging
          
          # Configuration du logging
          logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
          logger = logging.getLogger(__name__)
          
          def main():
              try:
                  # Paramètres depuis les arguments
                  n_trials = int(sys.argv[1]) if len(sys.argv) > 1 else 30
                  force_retrain = sys.argv[2].lower() == 'true' if len(sys.argv) > 2 else False
                  
                  logger.info(f"🚀 Démarrage entraînement LDA - {n_trials} essais")
                  
                  # Charger les données
                  if not os.path.exists("articles_scraped.csv"):
                      logger.error("❌ Fichier articles_scraped.csv introuvable")
                      sys.exit(1)
                  
                  df = pd.read_csv("articles_scraped.csv")
                  initial_count = len(df)
                  df = df.dropna(subset=['contenu'])
                  final_count = len(df)
                  
                  logger.info(f"📊 {initial_count} articles initiaux, {final_count} avec contenu")
                  
                  if final_count < 50 and not force_retrain:
                      logger.warning(f"⚠️ Données insuffisantes ({final_count} < 50)")
                      sys.exit(1)
                  
                  # Initialisation NLTK
                  try:
                      nltk.download('stopwords', quiet=True)
                      logger.info("✅ Stopwords NLTK téléchargés")
                  except Exception as e:
                      logger.warning(f"⚠️ Erreur téléchargement stopwords: {e}")
                  
                  # Stopwords (identiques à lda.py)
                  custom_stopwords = set(STOPWORDS)
                  try:
                      custom_stopwords.update(stopwords.words('french'))
                  except:
                      logger.warning("⚠️ Stopwords français non disponibles")
                  custom_stopwords.update(ENGLISH_STOP_WORDS)
                  custom_stopwords.update([
                      'selon', 'ce', 'cet', 'cette', 'dont', 'ainsi', 'hgroupe', 'ete', 'aussi','field','plus',
                      'dun', 'dune', 'cest', 'comme', 'juin', 'apres', 'deux', 'senegal','senegalais','juingroupe',
                      'sest','lors','egalement','sans','notamment', 'quil', 'tout', 'tous', 'fait','entre',
                      'titre','plusieurs','sous','faire','bien','meme','avant','toujours','cela','face','tres',
                      'leur','leurs','toute','toutes','vers','quelle','jai','etait','etais','senegalaise',
                      'alors','encore','avoir','nest', 'etre',
                  ])
                  
                  # Prétraitement (identique à lda.py)
                  def preprocess(text):
                      if pd.isna(text):
                          return ""
                      text = str(text).lower()
                      text = unidecode(text)
                      text = re.sub(r'\d+', '', text)
                      text = re.sub(r'[^\w\s]', '', text)
                      tokens = text.split()
                      tokens = [word for word in tokens if word not in custom_stopwords and len(word) > 2]
                      return ' '.join(tokens)
                  
                  logger.info("🔄 Prétraitement des textes...")
                  df['cleaned_content'] = df['contenu'].apply(preprocess)
                  
                  # Filtrer les textes vides après prétraitement
                  df = df[df['cleaned_content'].str.len() > 10]
                  logger.info(f"📝 {len(df)} articles après prétraitement")
                  
                  if len(df) < 20:
                      logger.error("❌ Trop peu d'articles après prétraitement")
                      sys.exit(1)
                  
                  # Vectorisation (identique à lda.py)
                  logger.info("🔤 Vectorisation...")
                  vectorizer = CountVectorizer(max_df=0.95, min_df=2)
                  X = vectorizer.fit_transform(df['cleaned_content'])
                  
                  logger.info(f"📊 Matrice: {X.shape[0]} documents, {X.shape[1]} mots")
                  
                  # Division train/validation
                  X_train, X_val = train_test_split(X, test_size=0.2, random_state=42)
                  
                  # Optimisation avec Optuna (identique à lda.py)
                  def objective(trial):
                      n_components = trial.suggest_int('n_components', 3, 15)
                      learning_decay = trial.suggest_float('learning_decay', 0.5, 0.9)
                      learning_offset = trial.suggest_int('learning_offset', 10, 100)
                      
                      lda = LatentDirichletAllocation(
                          n_components=n_components,
                          learning_method='online',
                          learning_decay=learning_decay,
                          learning_offset=learning_offset,
                          max_iter=10,
                          random_state=42
                      )
                      
                      try:
                          lda.fit(X_train)
                          perplexity = lda.perplexity(X_val)
                          return perplexity
                      except Exception as e:
                          logger.warning(f"⚠️ Erreur trial: {e}")
                          return float('inf')
                  
                  logger.info(f"🎯 Optimisation hyperparamètres ({n_trials} essais)...")
                  study = optuna.create_study(direction='minimize')
                  study.optimize(objective, n_trials=n_trials, show_progress_bar=False)
                  
                  best_params = study.best_params
                  logger.info(f"✅ Meilleurs paramètres: {best_params}")
                  logger.info(f"📊 Meilleure perplexité: {study.best_value:.2f}")
                  
                  # Entraînement final (identique à lda.py)
                  logger.info("🏋️ Entraînement final...")
                  best_lda = LatentDirichletAllocation(
                      n_components=best_params['n_components'],
                      learning_method='online',
                      learning_decay=best_params['learning_decay'],
                      learning_offset=best_params['learning_offset'],
                      max_iter=20,
                      random_state=42
                  )
                  
                  best_lda.fit(X)
                  
                  # Sauvegarde (identique à lda.py)
                  os.makedirs('./models', exist_ok=True)
                  model_path = './models/best_lda_model.joblib'
                  joblib.dump(best_lda, model_path)
                  
                  # Sauvegarder aussi le vectorizer
                  vectorizer_path = './models/vectorizer.joblib'
                  joblib.dump(vectorizer, vectorizer_path)
                  
                  logger.info("💾 Sauvegarde du modèle...")
                  logger.info("✅ Modèle sauvegardé avec succès!")
                  
                  # Test de chargement (identique à lda.py)
                  logger.info("🔍 Test de chargement...")
                  try:
                      test_model = joblib.load(model_path)
                      test_vectorizer = joblib.load(vectorizer_path)
                      logger.info("✅ Test de chargement réussi!")
                  except Exception as e:
                      logger.error(f"❌ Erreur test chargement: {e}")
                      sys.exit(1)
                  
                  # Métadonnées
                  metadata = {
                      'timestamp': datetime.now().isoformat(),
                      'n_documents': len(df),
                      'n_features': X.shape[1],
                      'best_params': best_params,
                      'best_perplexity': study.best_value,
                      'n_trials': n_trials
                  }
                  
                  import json
                  with open('./models/model_metadata.json', 'w') as f:
                      json.dump(metadata, f, indent=2)
                  
                  logger.info(f"💾 Modèle sauvegardé: {model_path}")
                  logger.info(f"🎉 Entraînement terminé avec succès!")
                  
                  print(f"SUCCESS:{best_params['n_components']}:{study.best_value:.2f}:{len(df)}")
                  
              except Exception as e:
                  logger.error(f"❌ Erreur générale: {e}")
                  import traceback
                  traceback.print_exc()
                  sys.exit(1)
          
          if __name__ == "__main__":
              main()
          EOF
          
      - name: Run LDA training
        id: training
        if: steps.check_data.outputs.sufficient_data == 'true' || github.event.inputs.force_retrain == 'true'
        run: |
          echo "🚀 Lancement de l'entraînement LDA..."
          
          N_TRIALS="${{ github.event.inputs.n_trials || '30' }}"
          FORCE_RETRAIN="${{ github.event.inputs.force_retrain || 'false' }}"
          
          # Utiliser le script modifié au lieu de lda.py directement
          python lda_workflow.py "$N_TRIALS" "$FORCE_RETRAIN" 2>&1 | tee training_log.txt
          
          # Capturer les résultats
          if grep -q "SUCCESS:" training_log.txt; then
            RESULT_LINE=$(grep "SUCCESS:" training_log.txt | tail -1)
            N_TOPICS=$(echo $RESULT_LINE | cut -d: -f2)
            PERPLEXITY=$(echo $RESULT_LINE | cut -d: -f3)
            N_DOCS=$(echo $RESULT_LINE | cut -d: -f4)
            
            echo "training_success=true" >> $GITHUB_OUTPUT
            echo "n_topics=$N_TOPICS" >> $GITHUB_OUTPUT
            echo "perplexity=$PERPLEXITY" >> $GITHUB_OUTPUT
            echo "n_documents=$N_DOCS" >> $GITHUB_OUTPUT
            
            echo "✅ Entraînement réussi!"
            echo "📊 Topics: $N_TOPICS, Perplexité: $PERPLEXITY, Documents: $N_DOCS"
          else
            echo "training_success=false" >> $GITHUB_OUTPUT
            echo "❌ Échec de l'entraînement"
          fi
          
      - name: Generate model report
        if: steps.training.outputs.training_success == 'true'
        run: |
          cat > generate_model_report.py << 'EOF'
          import joblib
          import json
          import os
          from datetime import datetime
          
          def generate_report():
              try:
                  # Charger les métadonnées
                  if os.path.exists('./models/model_metadata.json'):
                      with open('./models/model_metadata.json', 'r') as f:
                          metadata = json.load(f)
                  else:
                      metadata = {}
                  
                  # Générer le rapport
                  report = []
                  report.append("# 📊 Rapport d'Entraînement LDA")
                  report.append(f"**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}")
                  report.append("")
                  report.append("## 🎯 Résultats")
                  report.append(f"- **Nombre de topics:** {metadata.get('best_params', {}).get('n_components', 'N/A')}")
                  report.append(f"- **Perplexité:** {metadata.get('best_perplexity', 'N/A'):.2f}" if isinstance(metadata.get('best_perplexity'), (int, float)) else f"- **Perplexité:** {metadata.get('best_perplexity', 'N/A')}")
                  report.append(f"- **Documents traités:** {metadata.get('n_documents', 'N/A')}")
                  report.append(f"- **Vocabulaire:** {metadata.get('n_features', 'N/A')} mots")
                  report.append("")
                  report.append("## ⚙️ Hyperparamètres")
                  best_params = metadata.get('best_params', {})
                  for param, value in best_params.items():
                      report.append(f"- **{param}:** {value}")
                  report.append("")
                  report.append("## 📁 Fichiers générés")
                  report.append("- `best_lda_model.joblib` - Modèle LDA")
                  report.append("- `vectorizer.joblib` - Vectoriseur")
                  report.append("- `model_metadata.json` - Métadonnées")
                  
                  with open('model_report.md', 'w', encoding='utf-8') as f:
                      f.write('\n'.join(report))
                  
                  print("📋 Rapport généré avec succès")
                  
              except Exception as e:
                  print(f"❌ Erreur génération rapport: {e}")
          
          if __name__ == "__main__":
              generate_report()
          EOF
          
          python generate_model_report.py
          
      - name: Commit and push model updates
        if: steps.training.outputs.training_success == 'true'
        run: |
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Ajouter les fichiers du modèle
          git add models/
          
          # Vérifier s'il y a des changements
          if ! git diff --cached --quiet; then
            # Message de commit informatif
            N_TOPICS="${{ steps.training.outputs.n_topics }}"
            PERPLEXITY="${{ steps.training.outputs.perplexity }}"
            N_DOCS="${{ steps.training.outputs.n_documents }}"
            TIMESTAMP=$(date +'%Y-%m-%d %H:%M UTC')
            
            git commit -m "🤖 Weekly LDA model update - ${N_TOPICS} topics, perplexity ${PERPLEXITY} (${N_DOCS} docs) - ${TIMESTAMP}"
            git push origin master
            
            echo "✅ Modèle mis à jour et poussé avec succès"
            echo "📊 ${N_TOPICS} topics, perplexité ${PERPLEXITY}"
          else
            echo "ℹ️ Aucun changement détecté dans le modèle"
          fi
          
      - name: Upload training artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lda-training-${{ github.run_number }}
          path: |
            training_log.txt
            model_report.md
            models/model_metadata.json
          retention-days: 30
          
      - name: Final status report
        if: always()
        run: |
          echo "=== 📊 RAPPORT FINAL LDA ==="
          
          if [ "${{ steps.check_data.outputs.sufficient_data }}" == "true" ] || [ "${{ github.event.inputs.force_retrain }}" == "true" ]; then
            if [ "${{ steps.training.outputs.training_success }}" == "true" ]; then
              echo "✅ **SUCCÈS** - Modèle LDA réentraîné avec succès"
              echo "📊 Topics: ${{ steps.training.outputs.n_topics }}"
              echo "📈 Perplexité: ${{ steps.training.outputs.perplexity }}"
              echo "📄 Documents: ${{ steps.training.outputs.n_documents }}"
            else
              echo "❌ **ÉCHEC** - Erreur pendant l'entraînement"
            fi
          else
            echo "⚠️ **SAUTÉ** - Données insuffisantes (${{ steps.check_data.outputs.article_count }} articles)"
            echo "💡 Utilisez force_retrain=true pour forcer l'entraînement"
          fi
          
          echo "📅 Prochain entraînement: Lundi prochain à 5h UTC"
          
      - name: Cleanup temporary files
        if: always()
        run: |
          # Nettoyer les fichiers temporaires
          rm -f lda_workflow.py generate_model_report.py
          rm -f training_log.txt model_report.md
          
          echo "🧹 Nettoyage terminé"